{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.89951\n",
       "1    0.10049\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.target.value_counts(normalize=True)\n",
    "# 10% of targets are 1, 90% are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    var_0    var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  test_0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493   \n",
       "1  test_1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196   \n",
       "2  test_2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950   \n",
       "3  test_3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397   \n",
       "4  test_4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595   \n",
       "\n",
       "     var_7   var_8  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.2675  2.1337  ...  -2.1556  11.8495  -1.4300   2.4508  13.7112   2.4669   \n",
       "1  18.6316 -4.4131  ...  10.6165   8.8349   0.9403  10.1282  15.5765   0.4773   \n",
       "2  20.2537  1.5233  ...  -0.7484  10.9935   1.9803   2.1800  12.9813   2.1281   \n",
       "3  20.5660  3.3755  ...   9.5702   9.0766   1.6580   3.5813  15.1874   3.1656   \n",
       "4  10.6048  2.9890  ...   4.2259   9.1723   1.2835   3.3778  19.5542  -0.2860   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   4.3654  10.7200  15.4722  -8.7197  \n",
       "1  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID_code     object\n",
       "target       int64\n",
       "var_0      float64\n",
       "var_1      float64\n",
       "var_2      float64\n",
       "var_3      float64\n",
       "var_4      float64\n",
       "var_5      float64\n",
       "var_6      float64\n",
       "var_7      float64\n",
       "var_8      float64\n",
       "var_9      float64\n",
       "var_10     float64\n",
       "var_11     float64\n",
       "var_12     float64\n",
       "var_13     float64\n",
       "var_14     float64\n",
       "var_15     float64\n",
       "var_16     float64\n",
       "var_17     float64\n",
       "var_18     float64\n",
       "var_19     float64\n",
       "var_20     float64\n",
       "var_21     float64\n",
       "var_22     float64\n",
       "var_23     float64\n",
       "var_24     float64\n",
       "var_25     float64\n",
       "var_26     float64\n",
       "var_27     float64\n",
       "            ...   \n",
       "var_170    float64\n",
       "var_171    float64\n",
       "var_172    float64\n",
       "var_173    float64\n",
       "var_174    float64\n",
       "var_175    float64\n",
       "var_176    float64\n",
       "var_177    float64\n",
       "var_178    float64\n",
       "var_179    float64\n",
       "var_180    float64\n",
       "var_181    float64\n",
       "var_182    float64\n",
       "var_183    float64\n",
       "var_184    float64\n",
       "var_185    float64\n",
       "var_186    float64\n",
       "var_187    float64\n",
       "var_188    float64\n",
       "var_189    float64\n",
       "var_190    float64\n",
       "var_191    float64\n",
       "var_192    float64\n",
       "var_193    float64\n",
       "var_194    float64\n",
       "var_195    float64\n",
       "var_196    float64\n",
       "var_197    float64\n",
       "var_198    float64\n",
       "var_199    float64\n",
       "Length: 202, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_199    0\n",
       "var_61     0\n",
       "var_71     0\n",
       "var_70     0\n",
       "var_69     0\n",
       "var_68     0\n",
       "var_67     0\n",
       "var_66     0\n",
       "var_65     0\n",
       "var_64     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Dataset Have the Same Columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train and Test Datasets have the same columns?: True\n",
      "\n",
      "Variables not in test but in train :  set()\n"
     ]
    }
   ],
   "source": [
    "# Drop Different Columns from train and test\n",
    "print('\\nTrain and Test Datasets have the same columns?:',\n",
    "      train_df.drop('target',axis=1).columns.tolist()==test_df.columns.tolist())\n",
    "print(\"\\nVariables not in test but in train : \", \n",
    "      set(train_df.drop('target',axis=1).columns).difference(set(test_df.columns)))\n",
    "dif = list(set(train_df.drop('target',axis=1).columns).difference(set(test_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge train_df and test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7   var_8  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266 -4.9200  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  3.1468  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155 -4.9193  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250 -5.8609  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  6.2654  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_df[\"target\"].values\n",
    "train_id = train_df['ID_code'].values\n",
    "test_id = test_df['ID_code'].values\n",
    "\n",
    "df_merge = pd.concat([train_df.drop('target',axis=1),test_df],axis=0)\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['sum'] = df_merge.drop(['ID_code'], axis=1).sum(axis=1).values\n",
    "df_merge['mean'] = df_merge.drop(['ID_code'], axis=1).mean(axis=1).values\n",
    "df_merge['std'] = df_merge.drop(['ID_code'], axis=1).std(axis=1).values\n",
    "df_merge['min'] = df_merge.drop(['ID_code'], axis=1).min(axis=1).values\n",
    "df_merge['max'] = df_merge.drop(['ID_code'], axis=1).max(axis=1).values\n",
    "df_merge['skew'] = df_merge.drop(['ID_code'], axis=1).skew(axis=1).values\n",
    "df_merge['kurt'] = df_merge.drop(['ID_code'], axis=1).kurtosis(axis=1).values\n",
    "df_merge['med'] = df_merge.drop(['ID_code'], axis=1).median(axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore datraframes df_train and df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_merge[:len(train_df)]\n",
    "train_df[\"target\"] = y_train.tolist()\n",
    "test_df = df_merge[len(train_df):]\n",
    "\n",
    "train_df['ID_code'] = train_id\n",
    "test_df['ID_code'] = test_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV to find best params for LightGBM\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# params = {\"objective\" : [\"binary\"],\n",
    "#           \"metric\" : [\"auc\"],\n",
    "#           \"num_leaves\" : [3,9,15,60],\n",
    "#           'num_iterations' : [5000],\n",
    "#           'seed': [42],\n",
    "#           \"learning_rate\" : [0.05],\n",
    "#           \"bagging_fraction\" : [0.9],\n",
    "#           \"feature_fraction\" : [0.3],\n",
    "#           \"bagging_seed\" : [0]}\n",
    "\n",
    "# lgb_model = lgb.LGBMRegressor(verbose=200)\n",
    "\n",
    "# clf = GridSearchCV(estimator=lgb_model,\n",
    "#                    param_grid=params,\n",
    "#                    cv=StratifiedKFold(n_splits=3, shuffle=True), \n",
    "#                    refit=True, \n",
    "#                    verbose=True)\n",
    "\n",
    "# X = train_df.drop(['ID_code', 'target'], axis=1)\n",
    "# X_test = test_df.drop(['ID_code'], axis=1)\n",
    "# y = train_df.target\n",
    "# clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb_model ...\n",
      "\n",
      "\n",
      "LGBMRegressor(bagging_fraction=0.47842391064598466, bagging_seed=0,\n",
      "       boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "       feature_fraction=0.814688984534055, importance_type='split',\n",
      "       learning_rate=0.05, max_depth=-1, metric='auc',\n",
      "       min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=13,\n",
      "       min_split_gain=0.0, n_estimators=46, n_jobs=-1, nthread=2,\n",
      "       num_iterations=999999, num_leaves=4, num_threads=4,\n",
      "       objective='binary', random_state=None, reg_alpha=0.0,\n",
      "       reg_lambda=0.0, seed=42, silent=True, subsample=1.0,\n",
      "       subsample_for_bin=200000, subsample_freq=0)\n",
      "Fold: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[300]\ttraining's auc: 0.863429\tvalid_1's auc: 0.850387\n",
      "[600]\ttraining's auc: 0.890313\tvalid_1's auc: 0.873422\n",
      "[900]\ttraining's auc: 0.902578\tvalid_1's auc: 0.88288\n",
      "[1200]\ttraining's auc: 0.910027\tvalid_1's auc: 0.888219\n",
      "[1500]\ttraining's auc: 0.915042\tvalid_1's auc: 0.891576\n",
      "[1800]\ttraining's auc: 0.918719\tvalid_1's auc: 0.893707\n",
      "[2100]\ttraining's auc: 0.921895\tvalid_1's auc: 0.895127\n",
      "[2400]\ttraining's auc: 0.924872\tvalid_1's auc: 0.895729\n",
      "[2700]\ttraining's auc: 0.927939\tvalid_1's auc: 0.896012\n",
      "[3000]\ttraining's auc: 0.930679\tvalid_1's auc: 0.896208\n",
      "[3300]\ttraining's auc: 0.933325\tvalid_1's auc: 0.896381\n",
      "Early stopping, best iteration is:\n",
      "[3233]\ttraining's auc: 0.932689\tvalid_1's auc: 0.896506\n",
      "\n",
      "\n",
      "LGBMRegressor(bagging_fraction=0.3930849612234053, bagging_seed=0,\n",
      "       boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "       feature_fraction=0.5131061891237942, importance_type='split',\n",
      "       learning_rate=0.05, max_depth=-1, metric='auc',\n",
      "       min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=17,\n",
      "       min_split_gain=0.0, n_estimators=49, n_jobs=-1, nthread=2,\n",
      "       num_iterations=999999, num_leaves=19, num_threads=4,\n",
      "       objective='binary', random_state=None, reg_alpha=0.0,\n",
      "       reg_lambda=0.0, seed=42, silent=True, subsample=1.0,\n",
      "       subsample_for_bin=200000, subsample_freq=0)\n",
      "Fold: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[300]\ttraining's auc: 0.923099\tvalid_1's auc: 0.87938\n",
      "[600]\ttraining's auc: 0.947979\tvalid_1's auc: 0.891147\n",
      "[900]\ttraining's auc: 0.962848\tvalid_1's auc: 0.894479\n",
      "[1200]\ttraining's auc: 0.974568\tvalid_1's auc: 0.895139\n",
      "Early stopping, best iteration is:\n",
      "[1318]\ttraining's auc: 0.978203\tvalid_1's auc: 0.895351\n",
      "\n",
      "\n",
      "LGBMRegressor(bagging_fraction=0.3665794805103467, bagging_seed=0,\n",
      "       boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "       feature_fraction=0.9248814251410913, importance_type='split',\n",
      "       learning_rate=0.05, max_depth=-1, metric='auc',\n",
      "       min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=19,\n",
      "       min_split_gain=0.0, n_estimators=60, n_jobs=-1, nthread=2,\n",
      "       num_iterations=999999, num_leaves=29, num_threads=4,\n",
      "       objective='binary', random_state=None, reg_alpha=0.0,\n",
      "       reg_lambda=0.0, seed=42, silent=True, subsample=1.0,\n",
      "       subsample_for_bin=200000, subsample_freq=0)\n",
      "Fold: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[300]\ttraining's auc: 0.942558\tvalid_1's auc: 0.885037\n",
      "[600]\ttraining's auc: 0.969704\tvalid_1's auc: 0.896397\n",
      "[900]\ttraining's auc: 0.984756\tvalid_1's auc: 0.898118\n",
      "Early stopping, best iteration is:\n",
      "[953]\ttraining's auc: 0.986699\tvalid_1's auc: 0.898283\n",
      "\n",
      "\n",
      "LGBMRegressor(bagging_fraction=0.45038567548248787, bagging_seed=0,\n",
      "       boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "       feature_fraction=0.61727892886452, importance_type='split',\n",
      "       learning_rate=0.05, max_depth=-1, metric='auc',\n",
      "       min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=12,\n",
      "       min_split_gain=0.0, n_estimators=41, n_jobs=-1, nthread=2,\n",
      "       num_iterations=999999, num_leaves=16, num_threads=4,\n",
      "       objective='binary', random_state=None, reg_alpha=0.0,\n",
      "       reg_lambda=0.0, seed=42, silent=True, subsample=1.0,\n",
      "       subsample_for_bin=200000, subsample_freq=0)\n",
      "Fold: 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[300]\ttraining's auc: 0.91766\tvalid_1's auc: 0.874495\n",
      "[600]\ttraining's auc: 0.942374\tvalid_1's auc: 0.889064\n",
      "[900]\ttraining's auc: 0.956811\tvalid_1's auc: 0.892804\n",
      "Early stopping, best iteration is:\n",
      "[1072]\ttraining's auc: 0.963958\tvalid_1's auc: 0.893365\n",
      "\n",
      "\n",
      "LGBMRegressor(bagging_fraction=0.6223059316829357, bagging_seed=0,\n",
      "       boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "       feature_fraction=0.8834675940296495, importance_type='split',\n",
      "       learning_rate=0.05, max_depth=-1, metric='auc',\n",
      "       min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=11,\n",
      "       min_split_gain=0.0, n_estimators=69, n_jobs=-1, nthread=2,\n",
      "       num_iterations=999999, num_leaves=15, num_threads=4,\n",
      "       objective='binary', random_state=None, reg_alpha=0.0,\n",
      "       reg_lambda=0.0, seed=42, silent=True, subsample=1.0,\n",
      "       subsample_for_bin=200000, subsample_freq=0)\n",
      "Fold: 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[300]\ttraining's auc: 0.917359\tvalid_1's auc: 0.868978\n",
      "[600]\ttraining's auc: 0.941348\tvalid_1's auc: 0.883913\n",
      "[900]\ttraining's auc: 0.955596\tvalid_1's auc: 0.888556\n",
      "Early stopping, best iteration is:\n",
      "[1055]\ttraining's auc: 0.962334\tvalid_1's auc: 0.88901\n"
     ]
    }
   ],
   "source": [
    "X = train_df.drop(['ID_code', 'target'], axis=1)\n",
    "# X_test = pca.transform(test_df.drop(['ID_code'], axis=1).values)\n",
    "X_test = test_df.drop(['ID_code'], axis=1)\n",
    "y = train_df.target\n",
    "\n",
    "n_splits = 5\n",
    "VERBOSE_EVAL = 300\n",
    "STOP_ROUNDS = 100\n",
    "print(\"lgb_model ...\")\n",
    "\n",
    "prediction = np.zeros(test_df.shape[0])\n",
    "\n",
    "# folds = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for fold_n, (train_index, test_index) in enumerate(folds.split(X,y)):\n",
    "    NUM_ROUNDS = int(random.uniform(15, 75)) # Number of boosting trees\n",
    "    params = {\"objective\" : \"binary\",\n",
    "          \"metric\" : \"auc\",\n",
    "          \"num_leaves\" : int(random.uniform(2, 31)),\n",
    "          'min_data_in_leaf': int(random.uniform(10, 20)),\n",
    "          'num_iterations' : 999999, \n",
    "          'seed': 42,\n",
    "          \"learning_rate\" : 0.05,\n",
    "          \"bagging_fraction\" : random.uniform(0.3, 1),\n",
    "          \"feature_fraction\" : random.uniform(0.3, 1),\n",
    "          \"bagging_seed\" : 0,\n",
    "          \"num_threads\": 4}\n",
    "    lgb_model = lgb.LGBMRegressor(**params, n_estimators = NUM_ROUNDS, nthread = 2, n_jobs = -1)\n",
    "    print('\\n')\n",
    "    print(lgb_model)\n",
    "    \n",
    "    print('Fold:', fold_n)\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    lgb_model.fit(X_train, y_train, \n",
    "            eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='auc',\n",
    "            verbose=VERBOSE_EVAL, early_stopping_rounds=STOP_ROUNDS)\n",
    "    \n",
    "    y_pred = lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration_)\n",
    "    prediction += y_pred\n",
    "prediction /= n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = lgb_model.predict(pca.transform(test_df.drop(['ID_code'], axis=1).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Vector of probabilities\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_lgb = lgb_model.predict(pca.transform(train_df.drop(['ID_code', 'target'], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Vector of probabilities\n",
    "# y_train_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Optimal Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_threshhold(y_train, y_train_model, threshhold=0.5):\n",
    "#     y_train = y_train.copy()\n",
    "#     y_train_model = y_train_model.copy()\n",
    "#     y_train_model[y_train_model<threshhold] = 0\n",
    "#     y_train_model[y_train_model>=threshhold] = 1\n",
    "# #     print('Accuracy Score:', accuracy_score(y_train, y_train_model))\n",
    "#     return accuracy_score(y_train, y_train_model)\n",
    "\n",
    "# steps = np.linspace(0,1,1000)\n",
    "# threshholds = []\n",
    "# df_threshold = pd.DataFrame() #creates a new dataframe that's empty\n",
    "# for step_index in range(len(steps)):\n",
    "#     df_threshold.loc[step_index, 'StepValue'] = steps[step_index]\n",
    "#     df_threshold.loc[step_index, 'AccuracyScore'] = set_threshhold(y_train=train_df.target,\n",
    "#                                                                    y_train_model=y_train_lgb,\n",
    "#                                                                    threshhold=steps[step_index])\n",
    "    \n",
    "# max_index = int(df_threshold[df_threshold.AccuracyScore == df_threshold.AccuracyScore.max()].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.metrics import accuracy_score\n",
    "# threshold_otimo = df_threshold.StepValue.iloc[max_index]\n",
    "# y_train_lgb[y_train_lgb<threshold_otimo] = 0\n",
    "# y_train_lgb[y_train_lgb>=threshold_otimo] = 1\n",
    "# print('Optimal Accuracy Score:', accuracy_score(train_df.target.values, y_train_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# print(classification_report(train_df.target, y_train_lgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred[y_pred<threshold_otimo] = 0\n",
    "# y_pred[y_pred>=threshold_otimo] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = prediction\n",
    "test_df['target'] = y_pred\n",
    "\n",
    "submission_string = 'lgb_' + str(n_splits) + 'splits' + strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()) + '.csv'\n",
    "test_df.loc[:, ['ID_code', 'target']].to_csv(submission_string, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
