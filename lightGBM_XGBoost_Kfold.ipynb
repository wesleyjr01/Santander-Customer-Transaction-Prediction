{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('train.pkl')\n",
    "test_df = pd.read_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.89951\n",
       "1    0.10049\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.target.value_counts(normalize=True)\n",
    "# 10% of targets are 1, 90% are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    var_0    var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  test_0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493   \n",
       "1  test_1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196   \n",
       "2  test_2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950   \n",
       "3  test_3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397   \n",
       "4  test_4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595   \n",
       "\n",
       "     var_7   var_8  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.2675  2.1337  ...  -2.1556  11.8495  -1.4300   2.4508  13.7112   2.4669   \n",
       "1  18.6316 -4.4131  ...  10.6165   8.8349   0.9403  10.1282  15.5765   0.4773   \n",
       "2  20.2537  1.5233  ...  -0.7484  10.9935   1.9803   2.1800  12.9813   2.1281   \n",
       "3  20.5660  3.3755  ...   9.5702   9.0766   1.6580   3.5813  15.1874   3.1656   \n",
       "4  10.6048  2.9890  ...   4.2259   9.1723   1.2835   3.3778  19.5542  -0.2860   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   4.3654  10.7200  15.4722  -8.7197  \n",
       "1  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID_code     object\n",
       "target       int64\n",
       "var_0      float64\n",
       "var_1      float64\n",
       "var_2      float64\n",
       "var_3      float64\n",
       "var_4      float64\n",
       "var_5      float64\n",
       "var_6      float64\n",
       "var_7      float64\n",
       "var_8      float64\n",
       "var_9      float64\n",
       "var_10     float64\n",
       "var_11     float64\n",
       "var_12     float64\n",
       "var_13     float64\n",
       "var_14     float64\n",
       "var_15     float64\n",
       "var_16     float64\n",
       "var_17     float64\n",
       "var_18     float64\n",
       "var_19     float64\n",
       "var_20     float64\n",
       "var_21     float64\n",
       "var_22     float64\n",
       "var_23     float64\n",
       "var_24     float64\n",
       "var_25     float64\n",
       "var_26     float64\n",
       "var_27     float64\n",
       "            ...   \n",
       "var_170    float64\n",
       "var_171    float64\n",
       "var_172    float64\n",
       "var_173    float64\n",
       "var_174    float64\n",
       "var_175    float64\n",
       "var_176    float64\n",
       "var_177    float64\n",
       "var_178    float64\n",
       "var_179    float64\n",
       "var_180    float64\n",
       "var_181    float64\n",
       "var_182    float64\n",
       "var_183    float64\n",
       "var_184    float64\n",
       "var_185    float64\n",
       "var_186    float64\n",
       "var_187    float64\n",
       "var_188    float64\n",
       "var_189    float64\n",
       "var_190    float64\n",
       "var_191    float64\n",
       "var_192    float64\n",
       "var_193    float64\n",
       "var_194    float64\n",
       "var_195    float64\n",
       "var_196    float64\n",
       "var_197    float64\n",
       "var_198    float64\n",
       "var_199    float64\n",
       "Length: 202, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_199    0\n",
       "var_61     0\n",
       "var_71     0\n",
       "var_70     0\n",
       "var_69     0\n",
       "var_68     0\n",
       "var_67     0\n",
       "var_66     0\n",
       "var_65     0\n",
       "var_64     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Dataset Have the Same Columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train and Test Datasets have the same columns?: True\n",
      "\n",
      "Variables not in test but in train :  set()\n"
     ]
    }
   ],
   "source": [
    "# Drop Different Columns from train and test\n",
    "print('\\nTrain and Test Datasets have the same columns?:',\n",
    "      train_df.drop('target',axis=1).columns.tolist()==test_df.columns.tolist())\n",
    "print(\"\\nVariables not in test but in train : \", \n",
    "      set(train_df.drop('target',axis=1).columns).difference(set(test_df.columns)))\n",
    "dif = list(set(train_df.drop('target',axis=1).columns).difference(set(test_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=170)\n",
    "# X_INPUT = train_df.drop(['ID_code', 'target'], axis=1)\n",
    "# pca.fit(X_INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retained Variance on dimentional reduces data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_PCA = pca.transform(X_INPUT)\n",
    "# X_PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['ID_code', 'target'], axis=1)\n",
    "# X_test = pca.transform(test_df.drop(['ID_code'], axis=1).values)\n",
    "X_test = test_df.drop(['ID_code'], axis=1)\n",
    "y = train_df.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV to find best params for LightGBM\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# params = {\"objective\" : [\"binary\"],\n",
    "#           \"metric\" : [\"auc\"],\n",
    "#           \"num_leaves\" : [3,9,15,60],\n",
    "#           'num_iterations' : [5000],\n",
    "#           'seed': [42],\n",
    "#           \"learning_rate\" : [0.05],\n",
    "#           \"bagging_fraction\" : [0.9],\n",
    "#           \"feature_fraction\" : [0.3],\n",
    "#           \"bagging_seed\" : [0]}\n",
    "\n",
    "# lgb_model = lgb.LGBMRegressor(verbose=200)\n",
    "\n",
    "# clf = GridSearchCV(estimator=lgb_model,\n",
    "#                    param_grid=params,\n",
    "#                    cv=StratifiedKFold(n_splits=3, shuffle=True), \n",
    "#                    refit=True, \n",
    "#                    verbose=True)\n",
    "\n",
    "# X = train_df.drop(['ID_code', 'target'], axis=1)\n",
    "# X_test = test_df.drop(['ID_code'], axis=1)\n",
    "# y = train_df.target\n",
    "# clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Aggregation (Bagging) with LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb_model ...\n",
      "Fold: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[877]\ttraining's auc: 0.984\tvalid_1's auc: 0.891699\n",
      "Fold: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1000]\ttraining's auc: 0.988216\tvalid_1's auc: 0.894163\n",
      "Early stopping, best iteration is:\n",
      "[916]\ttraining's auc: 0.985448\tvalid_1's auc: 0.894263\n",
      "Fold: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1000]\ttraining's auc: 0.987974\tvalid_1's auc: 0.887144\n",
      "Early stopping, best iteration is:\n",
      "[940]\ttraining's auc: 0.986028\tvalid_1's auc: 0.887514\n",
      "Fold: 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1000]\ttraining's auc: 0.987971\tvalid_1's auc: 0.891138\n",
      "Early stopping, best iteration is:\n",
      "[916]\ttraining's auc: 0.985187\tvalid_1's auc: 0.891227\n",
      "Fold: 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[1000]\ttraining's auc: 0.987922\tvalid_1's auc: 0.897534\n",
      "Early stopping, best iteration is:\n",
      "[976]\ttraining's auc: 0.987232\tvalid_1's auc: 0.897612\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_splits = 5\n",
    "params = {\"objective\" : \"binary\",\n",
    "          \"metric\" : \"auc\",\n",
    "          \"num_leaves\" : 15,\n",
    "          'num_iterations' : 999999,\n",
    "          'seed': 42,\n",
    "          \"learning_rate\" : 0.05,\n",
    "          \"bagging_fraction\" : 0.85,\n",
    "          \"feature_fraction\" : 0.65,\n",
    "          \"bagging_seed\" : 0}\n",
    "\n",
    "folds = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "NUM_ROUNDS = 20000\n",
    "VERBOSE_EVAL = 1000\n",
    "STOP_ROUNDS = 100\n",
    "print(\"lgb_model ...\")\n",
    "lgb_model = lgb.LGBMRegressor(**params, n_estimators = NUM_ROUNDS, nthread = 2, n_jobs = -1)\n",
    "\n",
    "prediction = np.zeros(test_df.shape[0])\n",
    "\n",
    "for fold_n, (train_index, test_index) in enumerate(folds.split(X)):\n",
    "    print('Fold:', fold_n)\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    lgb_model.fit(X_train, y_train, \n",
    "            eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='auc',\n",
    "            verbose=VERBOSE_EVAL, early_stopping_rounds=STOP_ROUNDS)\n",
    "    \n",
    "    y_pred = lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration_)\n",
    "    prediction += y_pred\n",
    "prediction /= n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.684952\tvalid-auc:0.645482\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 100 rounds.\n",
      "[100]\ttrain-auc:0.875404\tvalid-auc:0.771069\n",
      "[200]\ttrain-auc:0.881034\tvalid-auc:0.77291\n",
      "[300]\ttrain-auc:0.888758\tvalid-auc:0.777638\n",
      "[400]\ttrain-auc:0.893148\tvalid-auc:0.780608\n",
      "[500]\ttrain-auc:0.8974\tvalid-auc:0.783181\n",
      "[600]\ttrain-auc:0.901383\tvalid-auc:0.785708\n",
      "[700]\ttrain-auc:0.905492\tvalid-auc:0.788133\n",
      "[800]\ttrain-auc:0.909318\tvalid-auc:0.790382\n",
      "[900]\ttrain-auc:0.913596\tvalid-auc:0.792574\n",
      "[1000]\ttrain-auc:0.917204\tvalid-auc:0.794605\n",
      "[1100]\ttrain-auc:0.920899\tvalid-auc:0.796406\n",
      "[1200]\ttrain-auc:0.924885\tvalid-auc:0.798687\n",
      "[1300]\ttrain-auc:0.928322\tvalid-auc:0.800772\n",
      "[1400]\ttrain-auc:0.931773\tvalid-auc:0.802783\n",
      "[1500]\ttrain-auc:0.934584\tvalid-auc:0.804449\n",
      "[1600]\ttrain-auc:0.937378\tvalid-auc:0.806003\n",
      "[1700]\ttrain-auc:0.940436\tvalid-auc:0.807901\n",
      "[1800]\ttrain-auc:0.943316\tvalid-auc:0.809671\n",
      "[1900]\ttrain-auc:0.946338\tvalid-auc:0.811844\n",
      "[1999]\ttrain-auc:0.94919\tvalid-auc:0.813793\n",
      "XGB Training Completed...\n"
     ]
    }
   ],
   "source": [
    "dev_X, val_X, dev_y, val_y = train_test_split(X_train, y_train, test_size = 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "def run_xgb(train_X, train_y, val_X, val_y, test_X):\n",
    "    params = {'objective': 'binary:logistic', \n",
    "          'eval_metric': 'auc',\n",
    "          'eta': 0.001,\n",
    "          'max_depth': 10, \n",
    "          'subsample': 0.6, \n",
    "          'colsample_bytree': 0.6,\n",
    "          'alpha':0.001,\n",
    "          'random_state': 42, \n",
    "          'silent': True}\n",
    "    \n",
    "    tr_data = xgb.DMatrix(train_X, train_y)\n",
    "    va_data = xgb.DMatrix(val_X, val_y)\n",
    "    \n",
    "    watchlist = [(tr_data, 'train'), (va_data, 'valid')]\n",
    "    \n",
    "    model_xgb = xgb.train(params, tr_data, 2000, watchlist, maximize=False,\n",
    "                          early_stopping_rounds = 100, verbose_eval=100)\n",
    "    \n",
    "    dtest = xgb.DMatrix(test_X)\n",
    "    xgb_pred_y = model_xgb.predict(dtest, ntree_limit=model_xgb.best_ntree_limit)\n",
    "    \n",
    "    return xgb_pred_y, model_xgb\n",
    "pred_test_xgb, model_xgb = run_xgb(dev_X, dev_y, val_X, val_y, X_test)\n",
    "print(\"XGB Training Completed...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = lgb_model.predict(pca.transform(test_df.drop(['ID_code'], axis=1).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Vector of probabilities\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_lgb = lgb_model.predict(pca.transform(train_df.drop(['ID_code', 'target'], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Vector of probabilities\n",
    "# y_train_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Optimal Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_threshhold(y_train, y_train_model, threshhold=0.5):\n",
    "#     y_train = y_train.copy()\n",
    "#     y_train_model = y_train_model.copy()\n",
    "#     y_train_model[y_train_model<threshhold] = 0\n",
    "#     y_train_model[y_train_model>=threshhold] = 1\n",
    "# #     print('Accuracy Score:', accuracy_score(y_train, y_train_model))\n",
    "#     return accuracy_score(y_train, y_train_model)\n",
    "\n",
    "# steps = np.linspace(0,1,1000)\n",
    "# threshholds = []\n",
    "# df_threshold = pd.DataFrame() #creates a new dataframe that's empty\n",
    "# for step_index in range(len(steps)):\n",
    "#     df_threshold.loc[step_index, 'StepValue'] = steps[step_index]\n",
    "#     df_threshold.loc[step_index, 'AccuracyScore'] = set_threshhold(y_train=train_df.target,\n",
    "#                                                                    y_train_model=y_train_lgb,\n",
    "#                                                                    threshhold=steps[step_index])\n",
    "    \n",
    "# max_index = int(df_threshold[df_threshold.AccuracyScore == df_threshold.AccuracyScore.max()].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.metrics import accuracy_score\n",
    "# threshold_otimo = df_threshold.StepValue.iloc[max_index]\n",
    "# y_train_lgb[y_train_lgb<threshold_otimo] = 0\n",
    "# y_train_lgb[y_train_lgb>=threshold_otimo] = 1\n",
    "# print('Optimal Accuracy Score:', accuracy_score(train_df.target.values, y_train_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# print(classification_report(train_df.target, y_train_lgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred[y_pred<threshold_otimo] = 0\n",
    "# y_pred[y_pred>=threshold_otimo] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = 0.7*prediction + 0.3*pred_test_xgb\n",
    "y_pred = prediction\n",
    "test_df['target'] = y_pred\n",
    "submission_string = 'lgb_xgb_' + strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()) + '.csv'\n",
    "test_df.loc[:, ['ID_code', 'target']].to_csv(submission_string, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
